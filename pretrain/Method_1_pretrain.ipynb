{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "81989e454ba3445c98fcdb47b48fd05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_738ca76babd64ad8b48a3bfd11890fa9",
              "IPY_MODEL_5411b4b72b77453181753b26f22a670c",
              "IPY_MODEL_63d66a9dda9a4a6caa2c5e46b7ac05d5"
            ],
            "layout": "IPY_MODEL_d75ccb630d0d4eeebed11f3c82afa0dd"
          }
        },
        "738ca76babd64ad8b48a3bfd11890fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca54fa80097e4182a2dcec4fbe286e9c",
            "placeholder": "​",
            "style": "IPY_MODEL_d8b90e195f5f438b8c8341dff2153453",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "5411b4b72b77453181753b26f22a670c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_374fc20cfe6e43d08a7976d14effbeea",
            "max": 109540,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ac7144551514cb5b320d9827b4100a6",
            "value": 109540
          }
        },
        "63d66a9dda9a4a6caa2c5e46b7ac05d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc9bf24fee1147199b28a61a4ac3fc34",
            "placeholder": "​",
            "style": "IPY_MODEL_380ed179d5ea4f829c95fd9a03fb08fb",
            "value": " 107k/107k [00:00&lt;00:00, 1.94MB/s]"
          }
        },
        "d75ccb630d0d4eeebed11f3c82afa0dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca54fa80097e4182a2dcec4fbe286e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b90e195f5f438b8c8341dff2153453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "374fc20cfe6e43d08a7976d14effbeea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ac7144551514cb5b320d9827b4100a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc9bf24fee1147199b28a61a4ac3fc34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "380ed179d5ea4f829c95fd9a03fb08fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f02e4df099644edea02d238a14136bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80907441abae4e16ba5dc6b1e1643631",
              "IPY_MODEL_64631f8a49f34d19bd364ae25ea5b813",
              "IPY_MODEL_1edcf323d57d4441aa98a966d28957e5"
            ],
            "layout": "IPY_MODEL_0fb4ef4b52504031b9ff49fda03720f6"
          }
        },
        "80907441abae4e16ba5dc6b1e1643631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b1a281cc5d0429fb2c372cba402d84f",
            "placeholder": "​",
            "style": "IPY_MODEL_7b825f7ebe6e49668fb48708fb410c61",
            "value": "Downloading special_tokens_map.json: 100%"
          }
        },
        "64631f8a49f34d19bd364ae25ea5b813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e18b1a0685f4b9f8e96cad56a508527",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e53e66bfad6416988a946f936329b04",
            "value": 112
          }
        },
        "1edcf323d57d4441aa98a966d28957e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_401b52b1e381495085fb069faaa7c0a5",
            "placeholder": "​",
            "style": "IPY_MODEL_aa602c46e708413988745fb47884f0ee",
            "value": " 112/112 [00:00&lt;00:00, 3.76kB/s]"
          }
        },
        "0fb4ef4b52504031b9ff49fda03720f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b1a281cc5d0429fb2c372cba402d84f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b825f7ebe6e49668fb48708fb410c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e18b1a0685f4b9f8e96cad56a508527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e53e66bfad6416988a946f936329b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "401b52b1e381495085fb069faaa7c0a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa602c46e708413988745fb47884f0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "031df15e26d0475f895b9186970c2733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d06c8f362f0d41b6a878b568c416e914",
              "IPY_MODEL_ce94ca57b92f43caa62034ae9cafd075",
              "IPY_MODEL_0422514f17254240808963f55ace0502"
            ],
            "layout": "IPY_MODEL_9d5265d8d5744cf1b1cada878a15202b"
          }
        },
        "d06c8f362f0d41b6a878b568c416e914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c32c810ec1f849028add213abbc9f48c",
            "placeholder": "​",
            "style": "IPY_MODEL_1678e7af97e64f8383d885e2452acd0c",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "ce94ca57b92f43caa62034ae9cafd075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_788b2655d4e74731bda48dde60d0db53",
            "max": 449,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98d1632e6b39495dae377f00c4685977",
            "value": 449
          }
        },
        "0422514f17254240808963f55ace0502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3019b01c58f04d02b7e69d8d0c523e58",
            "placeholder": "​",
            "style": "IPY_MODEL_74408fcfe8fd4b3abe8fccd230d32009",
            "value": " 449/449 [00:00&lt;00:00, 15.5kB/s]"
          }
        },
        "9d5265d8d5744cf1b1cada878a15202b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c32c810ec1f849028add213abbc9f48c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1678e7af97e64f8383d885e2452acd0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "788b2655d4e74731bda48dde60d0db53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98d1632e6b39495dae377f00c4685977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3019b01c58f04d02b7e69d8d0c523e58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74408fcfe8fd4b3abe8fccd230d32009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c1a228544114534a85846a4ae31701f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f0ea6188a85427191028f90d99784ce",
              "IPY_MODEL_8803234e750b4f4cad6fd202fc96e1c6",
              "IPY_MODEL_bdb0a1ecda4941b1b2891e6cb7e2e08f"
            ],
            "layout": "IPY_MODEL_9882d249cd75469b987d6d9d090b3dd5"
          }
        },
        "0f0ea6188a85427191028f90d99784ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb089f813fc94c03941fc3607f6a8f4e",
            "placeholder": "​",
            "style": "IPY_MODEL_aa46b4660ffb478c859f3b9a505858ad",
            "value": "Downloading config.json: 100%"
          }
        },
        "8803234e750b4f4cad6fd202fc96e1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c8c22d830a84f66ba4b659660e97e22",
            "max": 1629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88c0da2d406f46d99c5516a6efe83306",
            "value": 1629
          }
        },
        "bdb0a1ecda4941b1b2891e6cb7e2e08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc94588fe154b75bb8a147dc9a33646",
            "placeholder": "​",
            "style": "IPY_MODEL_718dd16c10a34e1794d7cf41c4432d99",
            "value": " 1.59k/1.59k [00:00&lt;00:00, 51.7kB/s]"
          }
        },
        "9882d249cd75469b987d6d9d090b3dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb089f813fc94c03941fc3607f6a8f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa46b4660ffb478c859f3b9a505858ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c8c22d830a84f66ba4b659660e97e22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c0da2d406f46d99c5516a6efe83306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcc94588fe154b75bb8a147dc9a33646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "718dd16c10a34e1794d7cf41c4432d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd2f93b089214e8e92ecb8fcafd8efea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34b46235f74a42e18b428e9e648ec1e1",
              "IPY_MODEL_cdd21382c7fd4f20bbe17f716353c4d1",
              "IPY_MODEL_1f742dc06f7b4977902a23f6ef97dc0b"
            ],
            "layout": "IPY_MODEL_50b50bc0c54c42198ecdab662f600e16"
          }
        },
        "34b46235f74a42e18b428e9e648ec1e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b658aa30c6b84c08a4e8d1eec7692c9d",
            "placeholder": "​",
            "style": "IPY_MODEL_58046c3f113d4ae7a58505fdb818e2d5",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "cdd21382c7fd4f20bbe17f716353c4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e23e8acc6c4d4ed782f52bd791d6c229",
            "max": 598070940,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dd9794c23bf4466a5dd8d853b869b1e",
            "value": 598070940
          }
        },
        "1f742dc06f7b4977902a23f6ef97dc0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ad56540dcc845809b90cb038ed1d04b",
            "placeholder": "​",
            "style": "IPY_MODEL_1c1088fd0f114299a02454f73e903c96",
            "value": " 570M/570M [00:14&lt;00:00, 45.9MB/s]"
          }
        },
        "50b50bc0c54c42198ecdab662f600e16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b658aa30c6b84c08a4e8d1eec7692c9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58046c3f113d4ae7a58505fdb818e2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e23e8acc6c4d4ed782f52bd791d6c229": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dd9794c23bf4466a5dd8d853b869b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ad56540dcc845809b90cb038ed1d04b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c1088fd0f114299a02454f73e903c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5up8tg35KuYB",
        "outputId": "b0fadd2c-d7ca-4458-db85-dca1d65fc09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install all needed libraries\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install pypinyin\n",
        "!pip install pkuseg\n",
        "!pip install evaluate\n",
        "!pip install bert_score\n",
        "!pip install statistics"
      ],
      "metadata": {
        "id": "RR1GfIUKG64D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d669da-9d8b-40be-fee6-532146281235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 57.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 63.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[K     |████████████████████████████████| 365 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 60.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 61.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.4.0 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pypinyin\n",
            "  Downloading pypinyin-0.47.1-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pypinyin\n",
            "Successfully installed pypinyin-0.47.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pkuseg\n",
            "  Downloading pkuseg-0.0.25-cp37-cp37m-manylinux1_x86_64.whl (50.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 50.2 MB 156 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pkuseg) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from pkuseg) (0.29.32)\n",
            "Installing collected packages: pkuseg\n",
            "Successfully installed pkuseg-0.0.25\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.2.2-py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.64.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.70.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.9.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.12.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.3.5.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2.4.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from evaluate) (3.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (3.8.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->evaluate) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.11-py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers>=3.0.0numpy in /usr/local/lib/python3.7/dist-packages (from bert_score) (4.21.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from bert_score) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from bert_score) (4.64.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert_score) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert_score) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from bert_score) (21.3)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bert_score) (1.12.1+cu113)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->bert_score) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert_score) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->bert_score) (4.1.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (0.9.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (3.8.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0numpy->bert_score) (3.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (2.10)\n",
            "Installing collected packages: bert-score\n",
            "Successfully installed bert-score-0.3.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting statistics\n",
            "  Downloading statistics-1.0.3.5.tar.gz (8.3 kB)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.7/dist-packages (from statistics) (0.17.1)\n",
            "Building wheels for collected packages: statistics\n",
            "  Building wheel for statistics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for statistics: filename=statistics-1.0.3.5-py3-none-any.whl size=7454 sha256=c7cf807c5faa90f57934795f933169e8af298aac74382e9df2e0dbcb104c5de5\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/09/e1/49ee45c0ce248a6e9c986aae82d32bbcba09c9f3b9d0c3406a\n",
            "Successfully built statistics\n",
            "Installing collected packages: statistics\n",
            "Successfully installed statistics-1.0.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4rnSkbQFmMR"
      },
      "outputs": [],
      "source": [
        "# import libraries for transformers, segmentation, pinyin and etc...\n",
        "from transformers import BertTokenizer, BartForConditionalGeneration, GPT2LMHeadModel, TextGenerationPipeline\n",
        "import pkuseg\n",
        "from pypinyin import Style, lazy_pinyin, pinyin\n",
        "import string\n",
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "import random\n",
        "import evaluate \n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to cuda if available\n",
        "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# set the tokenizer and model using pretrained model from huggingface\n",
        "tokenizer = BertTokenizer.from_pretrained(\"fnlp/bart-base-chinese\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"fnlp/bart-base-chinese\")\n",
        "seg = pkuseg.pkuseg()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "81989e454ba3445c98fcdb47b48fd05e",
            "738ca76babd64ad8b48a3bfd11890fa9",
            "5411b4b72b77453181753b26f22a670c",
            "63d66a9dda9a4a6caa2c5e46b7ac05d5",
            "d75ccb630d0d4eeebed11f3c82afa0dd",
            "ca54fa80097e4182a2dcec4fbe286e9c",
            "d8b90e195f5f438b8c8341dff2153453",
            "374fc20cfe6e43d08a7976d14effbeea",
            "5ac7144551514cb5b320d9827b4100a6",
            "bc9bf24fee1147199b28a61a4ac3fc34",
            "380ed179d5ea4f829c95fd9a03fb08fb",
            "f02e4df099644edea02d238a14136bc3",
            "80907441abae4e16ba5dc6b1e1643631",
            "64631f8a49f34d19bd364ae25ea5b813",
            "1edcf323d57d4441aa98a966d28957e5",
            "0fb4ef4b52504031b9ff49fda03720f6",
            "7b1a281cc5d0429fb2c372cba402d84f",
            "7b825f7ebe6e49668fb48708fb410c61",
            "0e18b1a0685f4b9f8e96cad56a508527",
            "5e53e66bfad6416988a946f936329b04",
            "401b52b1e381495085fb069faaa7c0a5",
            "aa602c46e708413988745fb47884f0ee",
            "031df15e26d0475f895b9186970c2733",
            "d06c8f362f0d41b6a878b568c416e914",
            "ce94ca57b92f43caa62034ae9cafd075",
            "0422514f17254240808963f55ace0502",
            "9d5265d8d5744cf1b1cada878a15202b",
            "c32c810ec1f849028add213abbc9f48c",
            "1678e7af97e64f8383d885e2452acd0c",
            "788b2655d4e74731bda48dde60d0db53",
            "98d1632e6b39495dae377f00c4685977",
            "3019b01c58f04d02b7e69d8d0c523e58",
            "74408fcfe8fd4b3abe8fccd230d32009",
            "1c1a228544114534a85846a4ae31701f",
            "0f0ea6188a85427191028f90d99784ce",
            "8803234e750b4f4cad6fd202fc96e1c6",
            "bdb0a1ecda4941b1b2891e6cb7e2e08f",
            "9882d249cd75469b987d6d9d090b3dd5",
            "cb089f813fc94c03941fc3607f6a8f4e",
            "aa46b4660ffb478c859f3b9a505858ad",
            "1c8c22d830a84f66ba4b659660e97e22",
            "88c0da2d406f46d99c5516a6efe83306",
            "bcc94588fe154b75bb8a147dc9a33646",
            "718dd16c10a34e1794d7cf41c4432d99",
            "dd2f93b089214e8e92ecb8fcafd8efea",
            "34b46235f74a42e18b428e9e648ec1e1",
            "cdd21382c7fd4f20bbe17f716353c4d1",
            "1f742dc06f7b4977902a23f6ef97dc0b",
            "50b50bc0c54c42198ecdab662f600e16",
            "b658aa30c6b84c08a4e8d1eec7692c9d",
            "58046c3f113d4ae7a58505fdb818e2d5",
            "e23e8acc6c4d4ed782f52bd791d6c229",
            "1dd9794c23bf4466a5dd8d853b869b1e",
            "9ad56540dcc845809b90cb038ed1d04b",
            "1c1088fd0f114299a02454f73e903c96"
          ]
        },
        "id": "XqqA5SwlG1D6",
        "outputId": "fe8c1ead-7ec0-450e-f700-700f9b5d4857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/107k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81989e454ba3445c98fcdb47b48fd05e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f02e4df099644edea02d238a14136bc3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/449 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "031df15e26d0475f895b9186970c2733"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c1a228544114534a85846a4ae31701f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
            "The class this function is called from is 'BertTokenizer'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/570M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd2f93b089214e8e92ecb8fcafd8efea"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the alphabet of capital letters\n",
        "alphabet = string.ascii_letters[26:]\n",
        "\n",
        "# The punctuation list\n",
        "PUNCS = set([\",\", \".\", \"?\", \"!\", \":\", \"，\", \"。\", \"？\", \"！\", \"：\"])\n",
        "\n",
        "# The yunmu dictionary for rhyming: all yunmus in the same number group rhyme.\n",
        "yunmus= {\n",
        "            \"0\":[\"a\", \"ia\", \"ua\", \"va\", \"üa\"],\n",
        "            \"1\":[\"e\", \"o\", \"uo\", \"ie\", \"ue\", \"üe\", \"ve\"],\n",
        "            \"2\":[\"u\"],\n",
        "            \"3\":[\"i\", \"ü\", \"v\"],\n",
        "            \"4\":[\"ai\", \"uai\"],\n",
        "            \"5\":[\"ao\", \"iao\"],\n",
        "            \"6\":[\"ou\", \"iu\", \"iou\"],\n",
        "            \"7\":[\"an\", \"ian\", \"uan\", \"üan\", \"van\"],\n",
        "            \"8\":[\"en\", \"in\", \"un\", \"ün\", \"vn\"],\n",
        "            \"9\":[\"ang\", \"iang\", \"uang\"],\n",
        "            \"10\":[\"eng\", \"ing\", \"ueng\", \"ong\", \"iong\"],\n",
        "            \"11\":[\"er\"],\n",
        "            \"12\":[\"ei\", \"ui\", \"uei\", \"vei\"],\n",
        "           }\n",
        "\n",
        "yun2id = {}\n",
        "for yid, yws in yunmus.items():\n",
        "    for w in yws:\n",
        "        yun2id[w] = yid\n"
      ],
      "metadata": {
        "id": "B8P0Roi-V-Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return the yunmu of the last word in the input text\n",
        "def yunmu_name(text):\n",
        "    w = text[-1]\n",
        "    if w in PUNCS and len(text) > 1:\n",
        "        w = text[-2]\n",
        "    yunmu = lazy_pinyin(w, style=Style.FINALS)\n",
        "    yunmu = yunmu[0]\n",
        "    return yunmu\n",
        "\n",
        "# Return the corresponding yunmu_id of the yunmu\n",
        "def yunmu_id(yunmu):\n",
        "    if yunmu in yun2id:\n",
        "        id = yun2id[yunmu]\n",
        "    else:\n",
        "        id = '-1'\n",
        "    return id\n",
        "\n",
        "# Return the corresponding schema of the sentences\n",
        "def sents_to_schema(sents):\n",
        "    m = 0\n",
        "    all_id = []\n",
        "    schema = ''\n",
        "    for sent in sents:\n",
        "        y_id = int(yunmu_id(yunmu_name(sent)))\n",
        "        if y_id in all_id:\n",
        "            schema += schema[all_id.index(y_id)]\n",
        "        else:\n",
        "            schema += alphabet[m]\n",
        "            m += 1\n",
        "        all_id.append(y_id)\n",
        "    return schema\n",
        "\n",
        "# clean the inputs, get rid of the spaces and punctuations and put the text into sentences in a list\n",
        "def clean_text(text):\n",
        "    text = text.replace(\" \", \"\")\n",
        "    for punc in PUNCS:\n",
        "        text = text.replace(punc, \" \")\n",
        "    sents = text.split()\n",
        "    return sents\n",
        "\n",
        "def encode_text(text):\n",
        "    sents = clean_text(text)\n",
        "    schema = sents_to_schema(sents)\n",
        "    new_sents = []\n",
        "    for i in range(len(sents)):\n",
        "        ori_text = sents[i]\n",
        "        segmentation = seg.cut(ori_text)\n",
        "        mask_word = segmentation[random.randint(0, len(segmentation)-1)]\n",
        "        new_sents.append(ori_text.replace(mask_word, '[MASK]'))\n",
        "    new_text = '，'.join(new_sents)\n",
        "    return new_text\n"
      ],
      "metadata": {
        "id": "w0mEfB1BuyKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = r'/content/drive/MyDrive/MSc_Project/dataset/train_eval_test'\n",
        "\n",
        "train_text = []\n",
        "train_label = []\n",
        "with open(os.path.join(data_path, 'train_data.txt'), 'r') as td:\n",
        "    for line in td:\n",
        "        line = line.rstrip()\n",
        "        train_label.append(line)\n",
        "        train_text.append(encode_text(line))\n",
        "\n",
        "eval_text = []\n",
        "eval_label = []\n",
        "with open(os.path.join(data_path, 'eval_data.txt'), 'r') as ed:\n",
        "    for line in ed:\n",
        "        line = line.rstrip()\n",
        "        eval_label.append(line)\n",
        "        eval_text.append(encode_text(line))\n",
        "\n",
        "test_text = []\n",
        "test_label = []\n",
        "with open(os.path.join(data_path, 'test_data.txt'), 'r') as ttd:\n",
        "    for line in ttd:\n",
        "        line = line.rstrip()\n",
        "        test_label.append(line)\n",
        "        test_text.append(encode_text(line))\n",
        "\n",
        "\n",
        "'''\n",
        "with open('/content/drive/MyDrive/MSc_Project/dataset/lyric.txt', 'r') as fp:\n",
        "    text = fp.read().split('\\n')\n",
        "\n",
        "for i in range(len(text)):\n",
        "    text[i] = encode_text(text[i])\n",
        "'''"
      ],
      "metadata": {
        "id": "q70aK9H3Z_SP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8f3915e7-069f-49ce-86c2-3bc91de87a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nwith open('/content/drive/MyDrive/MSc_Project/dataset/lyric.txt', 'r') as fp:\\n    text = fp.read().split('\\n')\\n\\nfor i in range(len(text)):\\n    text[i] = encode_text(text[i])\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(train_text, return_tensors='pt', max_length=128, truncation=True, padding='max_length')\n",
        "eval_inputs = tokenizer(eval_text, return_tensors='pt', max_length=128, truncation=True, padding='max_length')\n",
        "test_inputs = tokenizer(test_text, return_tensors='pt', max_length=128, truncation=True, padding='max_length')\n",
        "\n",
        "labels = tokenizer(train_label, return_tensors='pt', max_length=128, truncation=True, padding='max_length')\n",
        "eval_labels = tokenizer(eval_label, return_tensors='pt', max_length=128, truncation=True, padding='max_length')\n",
        "test_labels = tokenizer(test_label, return_tensors='pt', max_length=128, truncation=True, padding='max_length')"
      ],
      "metadata": {
        "id": "jThs-exMtTLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs['labels'] = labels.input_ids.detach().clone()\n",
        "eval_inputs['labels'] = eval_labels.input_ids.detach().clone()\n",
        "test_inputs['labels'] = test_labels.input_ids.detach().clone()\n",
        "\n",
        "#inputs.keys()"
      ],
      "metadata": {
        "id": "iwzHCSm5tdmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LyricsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ],
      "metadata": {
        "id": "SO5114x4t4Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = LyricsDataset(inputs)\n",
        "eval_dataset = LyricsDataset(eval_inputs)\n",
        "test_dataset = LyricsDataset(test_inputs)"
      ],
      "metadata": {
        "id": "AJodXBe1t7P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move our model to the selected device\n",
        "model.to(device)\n",
        "# activate training mode\n",
        "model.train()"
      ],
      "metadata": {
        "id": "GHvD0Uekt7VQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e573abf-e25b-4979-b3c1-a1bbb764a92f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): Embedding(21128, 768, padding_idx=0)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): Embedding(21128, 768, padding_idx=0)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(514, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): Embedding(21128, 768, padding_idx=0)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(514, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=21128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "# initialize optimizer\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n"
      ],
      "metadata": {
        "id": "SzwsNOaeuAhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# datetime object containing current date and time\n",
        "time_stamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
      ],
      "metadata": {
        "id": "VjhREL98nxMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "#args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", per_device_train_batch_size=4)\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir = f\"/content/drive/MyDrive/MSc_Project/args/Method_1/{time_stamp}\",\n",
        "    do_predict = True,\n",
        "    #per_device_train_batch_size = 8,\n",
        "    num_train_epochs = 5,\n",
        "    evaluation_strategy ='steps',\n",
        "    eval_steps = 300,\n",
        "    save_strategy ='steps',\n",
        "    save_steps = 300,\n",
        "    save_total_limit = 5, # Only last 5 models are saved. Older ones are deleted.\n",
        "    load_best_model_at_end = True,\n",
        "    predict_with_generate = True\n",
        ")"
      ],
      "metadata": {
        "id": "WgwAmihPeYcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    #compute_metrics=accuracy_metric,\n",
        ")"
      ],
      "metadata": {
        "id": "V2R0WvrJed3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()\n",
        "trainer.save_model()\n",
        "metrics = train_result.metrics\n",
        "\n",
        "trainer.log_metrics(\"train\", metrics)\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "trainer.save_state()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pYUmTNZCjxCb",
        "outputId": "6a25f44e-7fa4-4bb6-df0a-dbf0f2c70da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 38102\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 23815\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23815' max='23815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23815/23815 2:31:05, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.533243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.579900</td>\n",
              "      <td>0.510484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.579900</td>\n",
              "      <td>0.505614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.528400</td>\n",
              "      <td>0.499768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.524900</td>\n",
              "      <td>0.492751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.524900</td>\n",
              "      <td>0.487675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.521200</td>\n",
              "      <td>0.485748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.521200</td>\n",
              "      <td>0.480519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.514300</td>\n",
              "      <td>0.478258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.507300</td>\n",
              "      <td>0.474105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.507300</td>\n",
              "      <td>0.473513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.505500</td>\n",
              "      <td>0.474231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.505500</td>\n",
              "      <td>0.467936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.495900</td>\n",
              "      <td>0.466084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.490800</td>\n",
              "      <td>0.462200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.490800</td>\n",
              "      <td>0.470839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.462100</td>\n",
              "      <td>0.469623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.462100</td>\n",
              "      <td>0.467864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.428100</td>\n",
              "      <td>0.464586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.414800</td>\n",
              "      <td>0.461993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.414800</td>\n",
              "      <td>0.465105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.420100</td>\n",
              "      <td>0.460443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.420100</td>\n",
              "      <td>0.459987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.427000</td>\n",
              "      <td>0.462003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.420200</td>\n",
              "      <td>0.460675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.420200</td>\n",
              "      <td>0.455270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.422300</td>\n",
              "      <td>0.456583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.422300</td>\n",
              "      <td>0.456658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.424600</td>\n",
              "      <td>0.452295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.422500</td>\n",
              "      <td>0.451876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.422500</td>\n",
              "      <td>0.451090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.421400</td>\n",
              "      <td>0.460839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.421400</td>\n",
              "      <td>0.461297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.365800</td>\n",
              "      <td>0.462343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.358400</td>\n",
              "      <td>0.460059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.358400</td>\n",
              "      <td>0.461306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11100</td>\n",
              "      <td>0.362400</td>\n",
              "      <td>0.462514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11400</td>\n",
              "      <td>0.362400</td>\n",
              "      <td>0.460734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11700</td>\n",
              "      <td>0.362400</td>\n",
              "      <td>0.462025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.360300</td>\n",
              "      <td>0.460830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12300</td>\n",
              "      <td>0.360300</td>\n",
              "      <td>0.455519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12600</td>\n",
              "      <td>0.356800</td>\n",
              "      <td>0.457811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12900</td>\n",
              "      <td>0.356800</td>\n",
              "      <td>0.454951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13200</td>\n",
              "      <td>0.366700</td>\n",
              "      <td>0.457642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.362200</td>\n",
              "      <td>0.451712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13800</td>\n",
              "      <td>0.362200</td>\n",
              "      <td>0.454955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14100</td>\n",
              "      <td>0.367200</td>\n",
              "      <td>0.451616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14400</td>\n",
              "      <td>0.367200</td>\n",
              "      <td>0.468290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14700</td>\n",
              "      <td>0.338800</td>\n",
              "      <td>0.469714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.312700</td>\n",
              "      <td>0.469452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15300</td>\n",
              "      <td>0.312700</td>\n",
              "      <td>0.470079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15600</td>\n",
              "      <td>0.309200</td>\n",
              "      <td>0.470690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15900</td>\n",
              "      <td>0.309200</td>\n",
              "      <td>0.464741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16200</td>\n",
              "      <td>0.318200</td>\n",
              "      <td>0.469780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.470058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16800</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.467766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17100</td>\n",
              "      <td>0.318900</td>\n",
              "      <td>0.464041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17400</td>\n",
              "      <td>0.318900</td>\n",
              "      <td>0.465094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17700</td>\n",
              "      <td>0.318300</td>\n",
              "      <td>0.464555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>0.314700</td>\n",
              "      <td>0.460782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18300</td>\n",
              "      <td>0.314700</td>\n",
              "      <td>0.462223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18600</td>\n",
              "      <td>0.316200</td>\n",
              "      <td>0.460440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18900</td>\n",
              "      <td>0.316200</td>\n",
              "      <td>0.462340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19200</td>\n",
              "      <td>0.314700</td>\n",
              "      <td>0.477063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19500</td>\n",
              "      <td>0.285600</td>\n",
              "      <td>0.478162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19800</td>\n",
              "      <td>0.285600</td>\n",
              "      <td>0.477001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20100</td>\n",
              "      <td>0.279500</td>\n",
              "      <td>0.480692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20400</td>\n",
              "      <td>0.279500</td>\n",
              "      <td>0.478520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20700</td>\n",
              "      <td>0.284800</td>\n",
              "      <td>0.479984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>0.280900</td>\n",
              "      <td>0.477447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21300</td>\n",
              "      <td>0.280900</td>\n",
              "      <td>0.477874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21600</td>\n",
              "      <td>0.277400</td>\n",
              "      <td>0.476958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21900</td>\n",
              "      <td>0.277400</td>\n",
              "      <td>0.475736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22200</td>\n",
              "      <td>0.283200</td>\n",
              "      <td>0.476262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22500</td>\n",
              "      <td>0.281200</td>\n",
              "      <td>0.476366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22800</td>\n",
              "      <td>0.281200</td>\n",
              "      <td>0.475651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23100</td>\n",
              "      <td>0.282800</td>\n",
              "      <td>0.476018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23400</td>\n",
              "      <td>0.282800</td>\n",
              "      <td>0.475881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23700</td>\n",
              "      <td>0.279200</td>\n",
              "      <td>0.475591</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-300\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-300/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-300/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-600\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-600/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-600/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-900\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-900/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-900/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-1200\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-1200/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-1200/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-1500\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-1500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-1500/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-1800\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-1800/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-1800/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-300] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-2100\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-2100/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-2100/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-600] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-2400\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-2400/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-2400/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-900] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-2700\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-2700/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-2700/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-1200] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3000\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-1500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3300\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3300/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3300/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-1800] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3600\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3600/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3600/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-2100] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3900\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3900/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3900/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-2400] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-4200\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-4200/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-4200/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-2700] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-4500\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-4500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-4500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3000] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-4800\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-4800/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-4800/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3300] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-5100\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-5100/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-5100/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3600] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-5400\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-5400/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-5400/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-3900] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-5700\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-5700/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-5700/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-4200] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6000\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-4500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6300\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6300/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6300/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-4800] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6600\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6600/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6600/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-5100] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6900\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6900/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6900/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-5400] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-7200\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-7200/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-7200/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-5700] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-7500\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-7500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-7500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6000] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-7800\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-7800/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-7800/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6300] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-8100\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-8100/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-8100/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6600] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-8400\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-8400/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-8400/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-6900] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-8700\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-8700/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-8700/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-7200] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9000\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-7500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9300\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9300/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9300/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-7800] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9600\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9600/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9600/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-8100] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9900\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9900/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9900/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-8400] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-10200\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-10200/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-10200/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-8700] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-10500\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-10500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-10500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9000] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-10800\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-10800/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-10800/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9600] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-11100\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-11100/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-11100/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9900] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-11400\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-11400/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-11400/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-10200] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-11700\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-11700/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-11700/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-10500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12000\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-10800] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12300\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12300/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12300/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-11100] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12600\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12600/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12600/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-11400] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12900\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12900/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12900/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-11700] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-13200\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-13200/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-13200/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12000] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-13500\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-13500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-13500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12300] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-13800\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-13800/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-13800/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12600] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-14100\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-14100/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-14100/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-12900] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-14400\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-14400/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-14400/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-13200] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-14700\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-14700/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-14700/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-13500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15000\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-13800] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15300\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15300/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15300/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-14100] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15600\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15600/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15600/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-14400] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15900\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15900/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15900/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-14700] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-16200\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-16200/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-16200/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15000] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-16500\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-16500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-16500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15300] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-16800\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-16800/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-16800/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15600] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-17100\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-17100/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-17100/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-15900] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-17400\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-17400/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-17400/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-16200] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-17700\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-17700/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-17700/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-16500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18000\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-16800] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18300\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18300/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18300/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-17100] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18600\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18600/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18600/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-17400] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18900\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18900/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18900/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-17700] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-19200\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-19200/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-19200/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18000] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-19500\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-19500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-19500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18300] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-19800\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-19800/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-19800/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18600] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-20100\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-20100/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-20100/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-18900] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-20400\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-20400/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-20400/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-19200] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-20700\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-20700/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-20700/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-19500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21000\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-19800] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21300\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21300/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21300/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-20100] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21600\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21600/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21600/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-20400] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21900\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21900/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21900/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-20700] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-22200\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-22200/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-22200/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21000] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-22500\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-22500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-22500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21300] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-22800\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-22800/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-22800/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21600] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-23100\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-23100/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-23100/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-21900] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-23400\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-23400/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-23400/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-22200] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-23700\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-23700/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-23700/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-22500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/checkpoint-9300 (score: 0.4510895013809204).\n",
            "Saving model checkpoint to /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23\n",
            "Configuration saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/config.json\n",
            "Model weights saved in /content/drive/MyDrive/MSc_Project/args/Method_1/2022-09-01 12:49:23/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =        5.0\n",
            "  total_flos               = 13522907GF\n",
            "  train_loss               =     0.3797\n",
            "  train_runtime            = 2:31:08.43\n",
            "  train_samples_per_second =     21.008\n",
            "  train_steps_per_second   =      2.626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.evaluate()\n",
        "try:\n",
        "    perplexity = math.exp(metrics[\"eval_loss\"])\n",
        "except OverflowError:\n",
        "    perplexity = float(\"inf\")\n",
        "metrics[\"perplexity\"] = perplexity\n",
        "\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)"
      ],
      "metadata": {
        "id": "LHOiqqQXkXd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "2b3edee3-248a-4f57-91ad-b1dcde835ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 9525\n",
            "  Batch size = 8\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1191' max='1191' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1191/1191 00:53]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =        5.0\n",
            "  eval_loss               =     0.4511\n",
            "  eval_runtime            = 0:00:53.58\n",
            "  eval_samples_per_second =    177.767\n",
            "  eval_steps_per_second   =     22.228\n",
            "  perplexity              =       1.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '冷咖啡离开了杯垫，我忍住的情绪在很后面，决定一个人走，我没有后路可退，只能承受悲哀来陪，我的痛谁会在意，如果相遇是个意外，我愿意放手让你走，我不想让自己在沉醉，在悲伤中无法自拔'\n",
        "new_text = encode_text(text)\n",
        "import difflib"
      ],
      "metadata": {
        "id": "wzVw0N9HTV1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "o3MYr1lGTtsx",
        "outputId": "64b81b8f-18af-4b4b-ff2d-882215fd53c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'冷咖啡离开了杯垫，我忍住的情绪在很后面，决定一个人走，我没有后路可退，只能承受悲哀来陪，我的痛谁会在意，如果相遇是个意外，我愿意放手让你走，我不想让自己在沉醉，在悲伤中无法自拔'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"fnlp/bart-base-chinese\")\n",
        "import os\n",
        "PATH = r'/content/drive/MyDrive/MSc_Project/args/Method_1/2022-08-30 21:17:21/checkpoint-8500'\n",
        "#tokenizer = BertTokenizer.from_pretrained(os.path.join(PATH, 'vocab.txt'), local_files_only=True)\n",
        "model = BartForConditionalGeneration.from_pretrained(os.path.join(PATH, 'pytorch_model.bin'),config=os.path.join(PATH, 'config.json'), local_files_only=True)\n",
        "\n",
        "batch = tokenizer(new_text, return_tensors=\"pt\")\n",
        "generated_ids = model.generate(batch[\"input_ids\"], num_return_sequences = 50, max_length = 200, do_sample = True, temperature = 1.0, output_scores = True, return_dict_in_generate=True)\n",
        "result = tokenizer.batch_decode(generated_ids[\"sequences\"], skip_special_tokens=True)\n",
        "result = [s.replace(\" \", \"\") for s in result]"
      ],
      "metadata": {
        "id": "zCzGrC9BSvCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b2b5bb-ae75-422a-9fad-bb3850ac6627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/fnlp/bart-base-chinese/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/feb7fcba07a5cd52dab8daea7c7654f9f450cf4e2586eb946df713da5b44d5e4.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "loading file https://huggingface.co/fnlp/bart-base-chinese/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/fnlp/bart-base-chinese/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/c7a2ad3ce29650bde9ea8929d9d4414f1472f2eaee89e1700413a60725333838.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/fnlp/bart-base-chinese/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/e8916bb2271881244e34cad9e88d11ef38394196b1d328d76773fde6934c0ef9.4930bdcbc6f75dead7cdeadc249fdb55dcb3cd75bdcee68ee5fcd8aeb6e6e359\n",
            "loading configuration file https://huggingface.co/fnlp/bart-base-chinese/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e0ab1af8221a3166de9abfc42b6eb4275cfe6ee6ee31a99937350dfae50cc659.b46ea2f32c0c0a3eb762ff2b81ebfe0a058025072aa60e54714633acdd9ca36e\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"fnlp/bart-base-chinese\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 101,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 102,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 102,\n",
            "  \"forced_eos_token_id\": 102,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 128,\n",
            "      \"min_length\": 12,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_cnn\": {\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 62,\n",
            "      \"min_length\": 11,\n",
            "      \"num_beams\": 6\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
            "The class this function is called from is 'BertTokenizer'.\n",
            "loading configuration file /content/drive/MyDrive/MSc_Project/args/Method_1/2022-08-30 21:17:21/checkpoint-8500/config.json\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"fnlp/bart-base-chinese\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 101,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 102,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 102,\n",
            "  \"forced_eos_token_id\": 102,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 128,\n",
            "      \"min_length\": 12,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_cnn\": {\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 62,\n",
            "      \"min_length\": 11,\n",
            "      \"num_beams\": 6\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/MSc_Project/args/Method_1/2022-08-30 21:17:21/checkpoint-8500/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
            "\n",
            "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/MSc_Project/args/Method_1/2022-08-30 21:17:21/checkpoint-8500/pytorch_model.bin.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_rhyme = ['AAAAAAAAAA', 'AABBCCDDEE', 'ABABABABAB', 'ABCDEABCDE', 'ABCDEFGHIJ']\n",
        "\n",
        "def stat_metric(rhyme_metric):\n",
        "  avg = sum(rhyme_metric)/len(rhyme_metric)\n",
        "  maximum = max(rhyme_metric)\n",
        "  upper = sum(i >= 0.7 for i in rhyme_metric)\n",
        "  middle = sum(i >= 0.5 for i in rhyme_metric)\n",
        "  return [avg, maximum, upper, middle]\n",
        "#round(avg,3)\n",
        "\n",
        "def rhyme_stat(list_text, schema):\n",
        "  rhyme_metric = []\n",
        "  for i in range(len(result)):\n",
        "    new_schema = sents_to_schema(clean_text(result[i]))\n",
        "    new_schema = new_schema[:len(schema)]\n",
        "    temp = difflib.SequenceMatcher(None,schema,new_schema).ratio()\n",
        "    rhyme_metric.append(temp)\n",
        "  return stat_metric(rhyme_metric)"
      ],
      "metadata": {
        "id": "KtKJjR4PU_9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EXAMPLE 1:\n",
        "EX_1 = []\n",
        "for schema in list_of_rhyme:\n",
        "  EX_1.append(rhyme_stat(result, schema))"
      ],
      "metadata": {
        "id": "iB4NAS4-WXUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EX_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPCfJ4O6Vnnl",
        "outputId": "13e23a7b-9ba6-459f-833d-501a32e6a247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.09999999999999996, 0.1, 0, 0],\n",
              " [0.7700000000000002, 0.8, 50, 50],\n",
              " [0.39999999999999986, 0.4, 0, 0],\n",
              " [0.6999999999999998, 0.7, 50, 50],\n",
              " [0.5300000000000001, 0.6, 0, 50]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EXAMPLE 1:\n",
        "EX_1 = [[0, 0, 0, 0],[0, 0, 0, 0],[0, 0, 0, 0],[0, 0, 0, 0],[0, 0, 0, 0]]\n",
        "ALL_EX_1 = []\n",
        "iteration = 5\n",
        "for i in range(iteration):\n",
        "  batch = tokenizer(new_text, return_tensors=\"pt\")\n",
        "  generated_ids = model.generate(batch[\"input_ids\"], num_return_sequences = 50, max_length = 200, do_sample = True, temperature = 1.0, output_scores = True, return_dict_in_generate=True)\n",
        "  result = tokenizer.batch_decode(generated_ids[\"sequences\"], skip_special_tokens=True)\n",
        "  result = [s.replace(\" \", \"\") for s in result]\n",
        "  ALL_EX = []\n",
        "  for j in range(len(list_of_rhyme)):  \n",
        "    NEW_EX = rhyme_stat(result, list_of_rhyme[j])\n",
        "    ALL_EX.append(NEW_EX)\n",
        "    EX_1[j] = [sum(value) for value in zip(EX_1[j], NEW_EX)]\n",
        "  ALL_EX_1.append(ALL_EX)\n",
        "EX_1 = (np.array(EX_1) / iteration).tolist()"
      ],
      "metadata": {
        "id": "JGkmgCf6cqiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EX_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPLZOX9cfBd1",
        "outputId": "4bae23b7-9451-4a38-f068-cfffa6ab3b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.09999999999999996, 0.1, 0.0, 0.0],\n",
              " [0.7735999999999998, 0.8, 50.0, 50.0],\n",
              " [0.39999999999999986, 0.4, 0.0, 0.0],\n",
              " [0.6999999999999998, 0.7, 50.0, 50.0],\n",
              " [0.5264000000000001, 0.6, 0.0, 50.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ALL_EX_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3ar1Nqhhwii",
        "outputId": "5494f60e-87f9-46b7-9106-42fcf14325c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[0.09999999999999996, 0.1, 0, 0],\n",
              "  [0.7759999999999999, 0.8, 50, 50],\n",
              "  [0.39999999999999986, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.524, 0.6, 0, 50]],\n",
              " [[0.09999999999999996, 0.1, 0, 0],\n",
              "  [0.77, 0.8, 50, 50],\n",
              "  [0.39999999999999986, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.5300000000000001, 0.6, 0, 50]],\n",
              " [[0.09999999999999996, 0.1, 0, 0],\n",
              "  [0.7839999999999998, 0.8, 50, 50],\n",
              "  [0.39999999999999986, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.516, 0.6, 0, 50]],\n",
              " [[0.09999999999999996, 0.1, 0, 0],\n",
              "  [0.7739999999999996, 0.8, 50, 50],\n",
              "  [0.39999999999999986, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.5260000000000001, 0.6, 0, 50]],\n",
              " [[0.09999999999999996, 0.1, 0, 0],\n",
              "  [0.7639999999999999, 0.8, 50, 50],\n",
              "  [0.39999999999999986, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.5360000000000001, 0.6, 0, 50]]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EXAMPLE 2:\n",
        "EX_2 = [[0, 0, 0, 0],[0, 0, 0, 0],[0, 0, 0, 0],[0, 0, 0, 0],[0, 0, 0, 0]]\n",
        "ALL_EX_2 = []\n",
        "iteration = 5\n",
        "for i in range(iteration):\n",
        "  batch = tokenizer(new_text, return_tensors=\"pt\")\n",
        "  generated_ids = model.generate(batch[\"input_ids\"], num_return_sequences = 50, max_length = 200, do_sample = True, temperature = 1.0, output_scores = True, return_dict_in_generate=True)\n",
        "  result = tokenizer.batch_decode(generated_ids[\"sequences\"], skip_special_tokens=True)\n",
        "  result = [s.replace(\" \", \"\") for s in result]\n",
        "  ALL_EX = []\n",
        "  for j in range(len(list_of_rhyme)):  \n",
        "    NEW_EX = rhyme_stat(result, list_of_rhyme[j])\n",
        "    ALL_EX.append(NEW_EX)\n",
        "    EX_2[j] = [sum(value) for value in zip(EX_2[j], NEW_EX)]\n",
        "  ALL_EX_2.append(ALL_EX)\n",
        "EX_2 = (np.array(EX_2) / iteration).tolist()"
      ],
      "metadata": {
        "id": "hnq8eny5hwfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EX_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPXnwUFahwcq",
        "outputId": "c2eeb625-3d20-4586-e563-7792440e00f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.09999999999999996, 0.1, 0.0, 0.0],\n",
              " [0.7767999999999999, 0.8, 50.0, 50.0],\n",
              " [0.39999999999999986, 0.4, 0.0, 0.0],\n",
              " [0.6999999999999998, 0.7, 50.0, 50.0],\n",
              " [0.5232000000000001, 0.6, 0.0, 50.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ALL_EX_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSjujIjbgNyI",
        "outputId": "b2d151ee-e031-488e-90b1-9d7bb40d3432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[0.09999999999999996, 0.1, 0, 0],\n",
              "  [0.7759999999999997, 0.8, 50, 50],\n",
              "  [0.39999999999999986, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.5240000000000002, 0.6, 0, 50]],\n",
              " [[0.09999999999999996, 0.1, 0, 0],\n",
              "  [0.7819999999999997, 0.8, 50, 50],\n",
              "  [0.39999999999999986, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.518, 0.6, 0, 50]],\n",
              " [[0.09999999999999996, 0.1, 0, 0],\n",
              "  [0.7719999999999999, 0.8, 50, 50],\n",
              "  [0.39999999999999986, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.5280000000000001, 0.6, 0, 50]],\n",
              " [[0.09999999999999996, 0.1, 0, 0],\n",
              "  [0.7739999999999999, 0.8, 50, 50],\n",
              "  [0.39999999999999986, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.5260000000000001, 0.6, 0, 50]],\n",
              " [[0.09999999999999996, 0.1, 0, 0],\n",
              "  [0.7800000000000001, 0.8, 50, 50],\n",
              "  [0.39999999999999986, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.5200000000000001, 0.6, 0, 50]]]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EXAMPLE 3:\n",
        "EX_3 = [[0, 0, 0, 0],[0, 0, 0, 0],[0, 0, 0, 0],[0, 0, 0, 0],[0, 0, 0, 0]]\n",
        "ALL_EX_3 = []\n",
        "iteration = 5\n",
        "for i in range(iteration):\n",
        "  batch = tokenizer(new_text, return_tensors=\"pt\")\n",
        "  generated_ids = model.generate(batch[\"input_ids\"], num_return_sequences = 50, max_length = 200, do_sample = True, temperature = 1.0, output_scores = True, return_dict_in_generate=True)\n",
        "  result = tokenizer.batch_decode(generated_ids[\"sequences\"], skip_special_tokens=True)\n",
        "  result = [s.replace(\" \", \"\") for s in result]\n",
        "  ALL_EX = []\n",
        "  for j in range(len(list_of_rhyme)):  \n",
        "    NEW_EX = rhyme_stat(result, list_of_rhyme[j])\n",
        "    ALL_EX.append(NEW_EX)\n",
        "    EX_3[j] = [sum(value) for value in zip(EX_3[j], NEW_EX)]\n",
        "  ALL_EX_3.append(ALL_EX)\n",
        "EX_3 = (np.array(EX_3) / iteration).tolist()"
      ],
      "metadata": {
        "id": "afbcRE4NiBqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EX_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrb3imFniBnt",
        "outputId": "31418f99-1c18-4e8a-c34a-f435a39487e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.10079999999999996, 0.13999999999999999, 0.0, 0.0],\n",
              " [0.7775999999999998, 0.8, 50.0, 50.0],\n",
              " [0.3991999999999999, 0.4, 0.0, 0.0],\n",
              " [0.6995999999999998, 0.7, 49.8, 50.0],\n",
              " [0.5224, 0.6, 0.0, 50.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ALL_EX_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6-cOPXQiBku",
        "outputId": "91f7d7d4-bf16-4ec8-f6cf-0c07940edc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[0.10199999999999995, 0.2, 0, 0],\n",
              "  [0.77, 0.8, 50, 50],\n",
              "  [0.3979999999999999, 0.4, 0, 0],\n",
              "  [0.6979999999999998, 0.7, 49, 50],\n",
              "  [0.5300000000000001, 0.6, 0, 50]],\n",
              " [[0.09999999999999996, 0.1, 0, 0],\n",
              "  [0.7799999999999998, 0.8, 50, 50],\n",
              "  [0.39999999999999986, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.52, 0.6, 0, 50]],\n",
              " [[0.09999999999999996, 0.1, 0, 0],\n",
              "  [0.7759999999999999, 0.8, 50, 50],\n",
              "  [0.39999999999999986, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.524, 0.6, 0, 50]],\n",
              " [[0.09999999999999996, 0.1, 0, 0],\n",
              "  [0.7799999999999998, 0.8, 50, 50],\n",
              "  [0.39999999999999986, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.52, 0.6, 0, 50]],\n",
              " [[0.10199999999999995, 0.2, 0, 0],\n",
              "  [0.7819999999999999, 0.8, 50, 50],\n",
              "  [0.3979999999999999, 0.4, 0, 0],\n",
              "  [0.6999999999999998, 0.7, 50, 50],\n",
              "  [0.518, 0.6, 0, 50]]]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#TEXT 1:\n",
        "text = '最美的不是下雨天，是曾与你躲过雨的屋檐，泪流过的脸，是我记忆模糊一片，如果爱的路上没有了你，会不会有爱的晴天，如果没有你，我会在何处安身，哪怕一直走到了最后一个人，如果没有你'\n",
        "\n",
        "EX_1 = [[0.39679999999999993, 0.45999999999999996, 0.0, 1.0],\n",
        " [0.7179999999999999, 0.8, 49.2, 50.0],\n",
        " [0.5204, 0.62, 0.2, 30.2],\n",
        " [0.5176000000000002, 0.6, 0.0, 49.2],\n",
        " [0.418, 0.5, 0.0, 9.8]]\n",
        "\n",
        "EX_2 = [[0.39679999999999993, 0.5, 0.0, 1.8],\n",
        " [0.7184000000000001, 0.8, 49.0, 50.0],\n",
        " [0.5112, 0.62, 0.4, 27.8],\n",
        " [0.5184000000000001, 0.6, 0.0, 49.0],\n",
        " [0.4183999999999998, 0.5, 0.0, 10.2]]\n",
        "\n",
        "EX_3 = [[0.3971999999999999, 0.45999999999999996, 0.0, 0.6],\n",
        " [0.7168, 0.8, 49.2, 50.0],\n",
        " [0.5176000000000001, 0.62, 0.6, 29.2],\n",
        " [0.5168000000000001, 0.6, 0.0, 49.2],\n",
        " [0.41679999999999995, 0.5, 0.0, 9.2]]\n",
        "\n",
        "ALL_EX_1 = [[[0.3979999999999999, 0.4, 0, 0],\n",
        "  [0.716, 0.8, 50, 50],\n",
        "  [0.5280000000000001, 0.6, 0, 32],\n",
        "  [0.5160000000000001, 0.6, 0, 50],\n",
        "  [0.41599999999999987, 0.5, 0, 8]],\n",
        " [[0.39199999999999996, 0.4, 0, 0],\n",
        "  [0.7199999999999999, 0.8, 49, 50],\n",
        "  [0.518, 0.7, 1, 29],\n",
        "  [0.5200000000000001, 0.6, 0, 49],\n",
        "  [0.41999999999999993, 0.5, 0, 11]],\n",
        " [[0.39999999999999986, 0.5, 0, 3],\n",
        "  [0.72, 0.8, 49, 50],\n",
        "  [0.508, 0.6, 0, 27],\n",
        "  [0.5200000000000001, 0.6, 0, 49],\n",
        "  [0.4199999999999999, 0.5, 0, 11]],\n",
        " [[0.39599999999999996, 0.5, 0, 1],\n",
        "  [0.7099999999999997, 0.8, 48, 50],\n",
        "  [0.5299999999999998, 0.6, 0, 33],\n",
        "  [0.5100000000000001, 0.6, 0, 48],\n",
        "  [0.41, 0.5, 0, 7]],\n",
        " [[0.39799999999999996, 0.5, 0, 1],\n",
        "  [0.7239999999999998, 0.8, 50, 50],\n",
        "  [0.5179999999999999, 0.6, 0, 30],\n",
        "  [0.5220000000000001, 0.6, 0, 50],\n",
        "  [0.42399999999999993, 0.5, 0, 12]]]\n",
        "\n",
        "ALL_EX_2 = [[[0.38599999999999995, 0.5, 0, 1],\n",
        "  [0.7140000000000001, 0.8, 50, 50],\n",
        "  [0.508, 0.6, 0, 27],\n",
        "  [0.514, 0.6, 0, 50],\n",
        "  [0.4139999999999999, 0.5, 0, 7]],\n",
        " [[0.3979999999999999, 0.5, 0, 3],\n",
        "  [0.7179999999999999, 0.8, 49, 50],\n",
        "  [0.502, 0.6, 0, 26],\n",
        "  [0.5160000000000001, 0.6, 0, 49],\n",
        "  [0.418, 0.5, 0, 10]],\n",
        " [[0.39999999999999986, 0.5, 0, 1],\n",
        "  [0.7320000000000003, 0.8, 50, 50],\n",
        "  [0.49200000000000005, 0.6, 0, 23],\n",
        "  [0.534, 0.6, 0, 50],\n",
        "  [0.4319999999999997, 0.5, 0, 16]],\n",
        " [[0.3979999999999999, 0.5, 0, 2],\n",
        "  [0.7040000000000001, 0.8, 47, 50],\n",
        "  [0.5299999999999998, 0.7, 2, 32],\n",
        "  [0.504, 0.6, 0, 47],\n",
        "  [0.40399999999999997, 0.5, 0, 5]],\n",
        " [[0.4019999999999999, 0.5, 0, 2],\n",
        "  [0.7240000000000002, 0.8, 49, 50],\n",
        "  [0.5240000000000002, 0.6, 0, 31],\n",
        "  [0.524, 0.6, 0, 49],\n",
        "  [0.4239999999999998, 0.5, 0, 13]]]\n",
        "\n",
        "ALL_EX_3 = [[[0.3999999999999999, 0.5, 0, 1],\n",
        "  [0.7140000000000002, 0.8, 46, 50],\n",
        "  [0.5160000000000001, 0.7, 3, 28],\n",
        "  [0.5139999999999999, 0.6, 0, 46],\n",
        "  [0.4139999999999999, 0.5, 0, 11]],\n",
        " [[0.39599999999999996, 0.4, 0, 0],\n",
        "  [0.718, 0.8, 50, 50],\n",
        "  [0.5240000000000004, 0.6, 0, 31],\n",
        "  [0.5180000000000001, 0.6, 0, 50],\n",
        "  [0.418, 0.5, 0, 9]],\n",
        " [[0.39399999999999996, 0.4, 0, 0],\n",
        "  [0.7219999999999999, 0.8, 50, 50],\n",
        "  [0.4959999999999998, 0.6, 0, 24],\n",
        "  [0.5220000000000001, 0.6, 0, 50],\n",
        "  [0.4219999999999999, 0.5, 0, 11]],\n",
        " [[0.39799999999999996, 0.5, 0, 1],\n",
        "  [0.7120000000000001, 0.8, 50, 50],\n",
        "  [0.536, 0.6, 0, 34],\n",
        "  [0.512, 0.6, 0, 50],\n",
        "  [0.41199999999999987, 0.5, 0, 6]],\n",
        " [[0.39799999999999996, 0.5, 0, 1],\n",
        "  [0.7179999999999999, 0.8, 50, 50],\n",
        "  [0.516, 0.6, 0, 29],\n",
        "  [0.5180000000000001, 0.6, 0, 50],\n",
        "  [0.4179999999999999, 0.5, 0, 9]]]\n",
        "'''"
      ],
      "metadata": {
        "id": "WAZoFHVFkcZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dffccddd-9afe-4ecc-e7a6-cc1283ded942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n#TEXT 1:\\ntext = '最美的不是下雨天，是曾与你躲过雨的屋檐，泪流过的脸，是我记忆模糊一片，如果爱的路上没有了你，会不会有爱的晴天，如果没有你，我会在何处安身，哪怕一直走到了最后一个人，如果没有你'\\n\\nEX_1 = [[0.39679999999999993, 0.45999999999999996, 0.0, 1.0],\\n [0.7179999999999999, 0.8, 49.2, 50.0],\\n [0.5204, 0.62, 0.2, 30.2],\\n [0.5176000000000002, 0.6, 0.0, 49.2],\\n [0.418, 0.5, 0.0, 9.8]]\\n\\nEX_2 = [[0.39679999999999993, 0.5, 0.0, 1.8],\\n [0.7184000000000001, 0.8, 49.0, 50.0],\\n [0.5112, 0.62, 0.4, 27.8],\\n [0.5184000000000001, 0.6, 0.0, 49.0],\\n [0.4183999999999998, 0.5, 0.0, 10.2]]\\n\\nEX_3 = [[0.3971999999999999, 0.45999999999999996, 0.0, 0.6],\\n [0.7168, 0.8, 49.2, 50.0],\\n [0.5176000000000001, 0.62, 0.6, 29.2],\\n [0.5168000000000001, 0.6, 0.0, 49.2],\\n [0.41679999999999995, 0.5, 0.0, 9.2]]\\n\\nALL_EX_1 = [[[0.3979999999999999, 0.4, 0, 0],\\n  [0.716, 0.8, 50, 50],\\n  [0.5280000000000001, 0.6, 0, 32],\\n  [0.5160000000000001, 0.6, 0, 50],\\n  [0.41599999999999987, 0.5, 0, 8]],\\n [[0.39199999999999996, 0.4, 0, 0],\\n  [0.7199999999999999, 0.8, 49, 50],\\n  [0.518, 0.7, 1, 29],\\n  [0.5200000000000001, 0.6, 0, 49],\\n  [0.41999999999999993, 0.5, 0, 11]],\\n [[0.39999999999999986, 0.5, 0, 3],\\n  [0.72, 0.8, 49, 50],\\n  [0.508, 0.6, 0, 27],\\n  [0.5200000000000001, 0.6, 0, 49],\\n  [0.4199999999999999, 0.5, 0, 11]],\\n [[0.39599999999999996, 0.5, 0, 1],\\n  [0.7099999999999997, 0.8, 48, 50],\\n  [0.5299999999999998, 0.6, 0, 33],\\n  [0.5100000000000001, 0.6, 0, 48],\\n  [0.41, 0.5, 0, 7]],\\n [[0.39799999999999996, 0.5, 0, 1],\\n  [0.7239999999999998, 0.8, 50, 50],\\n  [0.5179999999999999, 0.6, 0, 30],\\n  [0.5220000000000001, 0.6, 0, 50],\\n  [0.42399999999999993, 0.5, 0, 12]]]\\n\\nALL_EX_2 = [[[0.38599999999999995, 0.5, 0, 1],\\n  [0.7140000000000001, 0.8, 50, 50],\\n  [0.508, 0.6, 0, 27],\\n  [0.514, 0.6, 0, 50],\\n  [0.4139999999999999, 0.5, 0, 7]],\\n [[0.3979999999999999, 0.5, 0, 3],\\n  [0.7179999999999999, 0.8, 49, 50],\\n  [0.502, 0.6, 0, 26],\\n  [0.5160000000000001, 0.6, 0, 49],\\n  [0.418, 0.5, 0, 10]],\\n [[0.39999999999999986, 0.5, 0, 1],\\n  [0.7320000000000003, 0.8, 50, 50],\\n  [0.49200000000000005, 0.6, 0, 23],\\n  [0.534, 0.6, 0, 50],\\n  [0.4319999999999997, 0.5, 0, 16]],\\n [[0.3979999999999999, 0.5, 0, 2],\\n  [0.7040000000000001, 0.8, 47, 50],\\n  [0.5299999999999998, 0.7, 2, 32],\\n  [0.504, 0.6, 0, 47],\\n  [0.40399999999999997, 0.5, 0, 5]],\\n [[0.4019999999999999, 0.5, 0, 2],\\n  [0.7240000000000002, 0.8, 49, 50],\\n  [0.5240000000000002, 0.6, 0, 31],\\n  [0.524, 0.6, 0, 49],\\n  [0.4239999999999998, 0.5, 0, 13]]]\\n\\nALL_EX_3 = [[[0.3999999999999999, 0.5, 0, 1],\\n  [0.7140000000000002, 0.8, 46, 50],\\n  [0.5160000000000001, 0.7, 3, 28],\\n  [0.5139999999999999, 0.6, 0, 46],\\n  [0.4139999999999999, 0.5, 0, 11]],\\n [[0.39599999999999996, 0.4, 0, 0],\\n  [0.718, 0.8, 50, 50],\\n  [0.5240000000000004, 0.6, 0, 31],\\n  [0.5180000000000001, 0.6, 0, 50],\\n  [0.418, 0.5, 0, 9]],\\n [[0.39399999999999996, 0.4, 0, 0],\\n  [0.7219999999999999, 0.8, 50, 50],\\n  [0.4959999999999998, 0.6, 0, 24],\\n  [0.5220000000000001, 0.6, 0, 50],\\n  [0.4219999999999999, 0.5, 0, 11]],\\n [[0.39799999999999996, 0.5, 0, 1],\\n  [0.7120000000000001, 0.8, 50, 50],\\n  [0.536, 0.6, 0, 34],\\n  [0.512, 0.6, 0, 50],\\n  [0.41199999999999987, 0.5, 0, 6]],\\n [[0.39799999999999996, 0.5, 0, 1],\\n  [0.7179999999999999, 0.8, 50, 50],\\n  [0.516, 0.6, 0, 29],\\n  [0.5180000000000001, 0.6, 0, 50],\\n  [0.4179999999999999, 0.5, 0, 9]]]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "TEXT 2:\n",
        "text = '冷咖啡离开了杯垫，我忍住的情绪在很后面，决定一个人走，我没有后路可退，只能承受悲哀来陪，我的痛谁会在意，如果相遇是个意外，我愿意放手让你走，我不想让自己在沉醉，在悲伤中无法自拔'\n",
        "\n",
        "EX_1 = [[0.2003999999999999, 0.21999999999999997, 0.0, 0.0],\n",
        " [0.6999999999999998, 0.7, 50.0, 50.0],\n",
        " [0.3004000000000003, 0.32, 0.0, 0.0],\n",
        " [0.6000000000000005, 0.6, 0.0, 50.0],\n",
        " [0.6164000000000003, 0.7, 8.2, 50.0]]\n",
        "\n",
        "EX_2 = [[0.19999999999999993, 0.2, 0.0, 0.0],\n",
        " [0.7003999999999998, 0.7200000000000001, 50.0, 50.0],\n",
        " [0.30000000000000027, 0.3, 0.0, 0.0],\n",
        " [0.6000000000000005, 0.6, 0.0, 50.0],\n",
        " [0.6120000000000003, 0.7, 6.0, 50.0]]\n",
        "\n",
        "EX_3 = [[0.19999999999999993, 0.2, 0.0, 0.0],\n",
        " [0.6999999999999998, 0.7, 50.0, 50.0],\n",
        " [0.30000000000000027, 0.3, 0.0, 0.0],\n",
        " [0.6000000000000005, 0.6, 0.0, 50.0],\n",
        " [0.6140000000000004, 0.7, 7.0, 50.0]]\n",
        "\n",
        "ALL_EX_1 = [[[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6180000000000004, 0.7, 9, 50]],\n",
        " [[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6140000000000003, 0.7, 7, 50]],\n",
        " [[0.20199999999999993, 0.3, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30200000000000027, 0.4, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6200000000000003, 0.7, 10, 50]],\n",
        " [[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6100000000000004, 0.7, 5, 50]],\n",
        " [[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6200000000000003, 0.7, 10, 50]]]\n",
        "\n",
        "ALL_EX_2 = [[[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6120000000000004, 0.7, 6, 50]],\n",
        " [[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.7019999999999997, 0.8, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6120000000000004, 0.7, 6, 50]],\n",
        " [[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6100000000000003, 0.7, 5, 50]],\n",
        " [[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6140000000000003, 0.7, 7, 50]],\n",
        " [[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6120000000000004, 0.7, 6, 50]]]\n",
        "\n",
        "ALL_EX_3 = [[[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6180000000000004, 0.7, 9, 50]],\n",
        " [[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6160000000000003, 0.7, 8, 50]],\n",
        " [[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6160000000000003, 0.7, 8, 50]],\n",
        " [[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6100000000000005, 0.7, 5, 50]],\n",
        " [[0.19999999999999993, 0.2, 0, 0],\n",
        "  [0.6999999999999998, 0.7, 50, 50],\n",
        "  [0.30000000000000027, 0.3, 0, 0],\n",
        "  [0.6000000000000005, 0.6, 0, 50],\n",
        "  [0.6100000000000004, 0.7, 5, 50]]]\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "jPrK-GHziBco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8534aa2d-4bf1-40d5-ece4-dbe8a7c51f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nTEXT 2:\\ntext = '冷咖啡离开了杯垫，我忍住的情绪在很后面，决定一个人走，我没有后路可退，只能承受悲哀来陪，我的痛谁会在意，如果相遇是个意外，我愿意放手让你走，我不想让自己在沉醉，在悲伤中无法自拔'\\n\\nEX_1 = [[0.2003999999999999, 0.21999999999999997, 0.0, 0.0],\\n [0.6999999999999998, 0.7, 50.0, 50.0],\\n [0.3004000000000003, 0.32, 0.0, 0.0],\\n [0.6000000000000005, 0.6, 0.0, 50.0],\\n [0.6164000000000003, 0.7, 8.2, 50.0]]\\n\\nEX_2 = [[0.19999999999999993, 0.2, 0.0, 0.0],\\n [0.7003999999999998, 0.7200000000000001, 50.0, 50.0],\\n [0.30000000000000027, 0.3, 0.0, 0.0],\\n [0.6000000000000005, 0.6, 0.0, 50.0],\\n [0.6120000000000003, 0.7, 6.0, 50.0]]\\n\\nEX_3 = [[0.19999999999999993, 0.2, 0.0, 0.0],\\n [0.6999999999999998, 0.7, 50.0, 50.0],\\n [0.30000000000000027, 0.3, 0.0, 0.0],\\n [0.6000000000000005, 0.6, 0.0, 50.0],\\n [0.6140000000000004, 0.7, 7.0, 50.0]]\\n\\nALL_EX_1 = [[[0.19999999999999993, 0.2, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6180000000000004, 0.7, 9, 50]],\\n [[0.19999999999999993, 0.2, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6140000000000003, 0.7, 7, 50]],\\n [[0.20199999999999993, 0.3, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30200000000000027, 0.4, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6200000000000003, 0.7, 10, 50]],\\n [[0.19999999999999993, 0.2, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6100000000000004, 0.7, 5, 50]],\\n [[0.19999999999999993, 0.2, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6200000000000003, 0.7, 10, 50]]]\\n\\nALL_EX_2 = [[[0.19999999999999993, 0.2, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6120000000000004, 0.7, 6, 50]],\\n [[0.19999999999999993, 0.2, 0, 0],\\n  [0.7019999999999997, 0.8, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6120000000000004, 0.7, 6, 50]],\\n [[0.19999999999999993, 0.2, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6100000000000003, 0.7, 5, 50]],\\n [[0.19999999999999993, 0.2, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6140000000000003, 0.7, 7, 50]],\\n [[0.19999999999999993, 0.2, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6120000000000004, 0.7, 6, 50]]]\\n\\nALL_EX_3 = [[[0.19999999999999993, 0.2, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6180000000000004, 0.7, 9, 50]],\\n [[0.19999999999999993, 0.2, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6160000000000003, 0.7, 8, 50]],\\n [[0.19999999999999993, 0.2, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6160000000000003, 0.7, 8, 50]],\\n [[0.19999999999999993, 0.2, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6100000000000005, 0.7, 5, 50]],\\n [[0.19999999999999993, 0.2, 0, 0],\\n  [0.6999999999999998, 0.7, 50, 50],\\n  [0.30000000000000027, 0.3, 0, 0],\\n  [0.6000000000000005, 0.6, 0, 50],\\n  [0.6100000000000004, 0.7, 5, 50]]]\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}